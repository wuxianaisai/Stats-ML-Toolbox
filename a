```python
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Imputation Demo\n",
    "\n",
    "This notebook demonstrates the use of the `auto_impute` function from **Stats-ML-Toolbox** to handle missing values in the Titanic dataset from Kaggle. The goal is to impute missing values in `Age` (numeric) and `Embarked` (categorical) columns and evaluate the impact on a classification model predicting survival (`Survived`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Load necessary libraries and the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scripts.imputation import auto_impute\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = pd.read_csv('projects/titanic_imputation/data/train.csv')\n",
    "\n",
    "# Display basic info\n",
    "print('Dataset Info:')\n",
    "print(df.info())\n",
    "print('\\nMissing Values:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Select relevant features, define numeric and categorical columns, and introduce additional missing values for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex', 'Embarked']\n",
    "target = 'Survived'\n",
    "df = df[features + [target]]\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_cols = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "# Introduce additional missing values (10% in 'Age' and 5% in 'Embarked')\n",
    "np.random.seed(42)\n",
    "df.loc[df.sample(frac=0.1, random_state=42).index, 'Age'] = np.nan\n",
    "df.loc[df.sample(frac=0.05, random_state=42).index, 'Embarked'] = np.nan\n",
    "\n",
    "print('\\nMissing Values After Adding:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply auto_impute\n",
    "\n",
    "Use `auto_impute` to find the best imputation strategy for missing values. We use a RandomForestClassifier to evaluate imputation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model for evaluation\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Apply auto_impute\n",
    "best_df, results_df, best_info = auto_impute(\n",
    "    df=df,\n",
    "    target_col=target,\n",
    "    numeric_cols=numeric_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    models=[model],\n",
    "    metric='accuracy',\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    visualize=True,\n",
    "    save_plot=True,\n",
    "    plot_path='projects/titanic_imputation/imputation_results.png',\n",
    "    n_jobs=2,\n",
    "    save_best_path='projects/titanic_imputation/best_imputed.csv'\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print('\\nBest Imputation Strategy:')\n",
    "print(best_info)\n",
    "print('\\nResults Table:')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model Performance\n",
    "\n",
    "Train a RandomForestClassifier on the imputed dataset and compare its performance to a baseline (e.g., dropping rows with missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Baseline: Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "X_dropped = df_dropped[numeric_cols + categorical_cols]\n",
    "X_dropped = pd.get_dummies(X_dropped, columns=categorical_cols)\n",
    "y_dropped = df_dropped[target]\n",
    "\n",
    "# Split data\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_dropped, y_dropped, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate baseline\n",
    "model_baseline = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_baseline.fit(X_train_d, y_train_d)\n",
    "y_pred_d = model_baseline.predict(X_test_d)\n",
    "baseline_accuracy = accuracy_score(y_test_d, y_pred_d)\n",
    "\n",
    "# Imputed data\n",
    "X_imputed = best_df[numeric_cols + categorical_cols]\n",
    "X_imputed = pd.get_dummies(X_imputed, columns=categorical_cols)\n",
    "y_imputed = best_df[target]\n",
    "\n",
    "# Split data\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(X_imputed, y_imputed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate on imputed data\n",
    "model_imputed = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_imputed.fit(X_train_i, y_train_i)\n",
    "y_pred_i = model_imputed.predict(X_test_i)\n",
    "imputed_accuracy = accuracy_score(y_test_i, y_pred_i)\n",
    "\n",
    "print(f'\\nBaseline Accuracy (Drop NA): {baseline_accuracy:.4f}')\n",
    "print(f'Imputed Accuracy (auto_impute): {imputed_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "The `auto_impute` function successfully handled missing values in the Titanic dataset, selecting the best imputation strategy based on cross-validation accuracy. The imputed dataset improved model performance compared to simply dropping missing values, demonstrating the value of the **Stats-ML-Toolbox**. The results table and visualization provide insights into the effectiveness of each imputation strategy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
```
